[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mostly Monte Carlo Seminar Series",
    "section": "",
    "text": "A monthly seminar on the theory and practice of Monte Carlo in statistics and data science.\nHeld on the 2nd Friday of each month (approximately) at the PariSanté Campus.\nOrganised by Andrea Bertazzi and Joshua Bon."
  },
  {
    "objectID": "index.html#join-the-mailing-list",
    "href": "index.html#join-the-mailing-list",
    "title": "Mostly Monte Carlo Seminar Series",
    "section": "Join the mailing list",
    "text": "Join the mailing list\n\n&lt;p&gt;Loading…&lt;/p&gt;"
  },
  {
    "objectID": "sem/s202X_XX.html",
    "href": "sem/s202X_XX.html",
    "title": "MONTH",
    "section": "",
    "text": "Room: Salle XX, PariSanté Campus\n\n\nTitle\nSpeaker Affiliation\nAbstract\n\n\nTitle\nSpeaker Affiliation\nAbstract"
  },
  {
    "objectID": "sem/2023/s2023_12.html",
    "href": "sem/2023/s2023_12.html",
    "title": "December",
    "section": "",
    "text": "Salle 08, PariSanté Campus\n\n\nSVBMC: Fast post-processing Bayesian inference with noisy evaluations of the likelihood\nGrégoire Clarté University of Helsinki, University of Edinburgh\nIn many cases, the exact likelihood is unavailable, and can only be accessed through a noisy and expensive process – for example, in Plasma Physics. Furthermore, Bayesian inference often comes in at a second moment, for example after running an optimization algorithm to find a MAP estimate. To tackle both these issues, we introduce Sparse Variational Bayesian Monte Carlo (SVBMC), a method for fast “post-processes” Bayesian inference for models with black-box and noisy likelihoods. SVBMC reuses all existing target density evaluations – for example, from previous optimizations or partial Markov Chain Monte Carlo runs – to build a sparse Gaussian process (GP) surrogate model of the log posterior density. Uncertain regions of the surrogate are then refined via active learning as needed. Our work builds on the Variational Bayesian Monte Carlo (VBMC) framework for sample-efficient inference, with several novel contributions. First, we make VBMC scalable to a large number of pre-existing evaluations via sparse GP regression, deriving novel Bayesian quadrature formulae and acquisition functions for active learning with sparse GPs. Second, we introduce noise shaping, a general technique to induce the sparse GP approximation to focus on high posterior density regions. Third, we prove theoretical results in support of the SVBMC refinement procedure. We validate our method on a variety of challenging synthetic scenarios and real-world applications. We find that SVBMC consistently builds good posterior approximations by post-processing of existing model evaluations from different sources, often requiring only a small number of additional density evaluations.\n\n\nVariance reduction using control variates and importance sampling for applications in computational statistical physics\nUrbain Vaes INRIA, CERMICS\nThe scaling of the mobility coefficient associated with two-dimensional Langevin dynamics in a periodic potential as the friction vanishes is not well understood. Theoretical results are lacking, and numerical calculation of the mobility in the underdamped regime is challenging. In the first part of this talk, I will present a new variance reduction approach based on control variates for efficiently estimating the mobility of Langevin-type dynamics, together with numerical experiments illustrating the performance of the approach.\nIn the second part of this talk, we study an importance sampling approach for calculating averages with respect to multimodal probability distributions. Traditional Markov chain Monte Carlo methods to this end, which are based on time averages along a realization of a Markov process ergodic with respect to the target probability distribution, are usually plagued by a large variance due to the metastability of the process. The estimator we study is based on an ergodic average along a realization of an overdamped Langevin process for a modified potential. We obtain an explicit expression for the optimal biasing potential in dimension 1 and propose a general numerical approach for approximating the optimal potential in the multi-dimensional setting.",
    "crumbs": [
      "Home",
      "2023",
      "December"
    ]
  },
  {
    "objectID": "sem/2023/s2023_11.html",
    "href": "sem/2023/s2023_11.html",
    "title": "November",
    "section": "",
    "text": "Salle 06, PariSanté Campus\n\n\nMonte Carlo guided Diffusion models for Bayesian linear inverse problems\nYazid Janati El Idrissi CMAP, École Polytechnique\nIll-posed linear inverse problems arise frequently in various applications, from computational photography to medical imaging. A recent line of research exploits Bayesian inference with informative priors to handle the ill-posedness of such problems. Amongst such priors, score-based generative models (SGM) have recently been successfully applied to several different inverse problems. In this study, we exploit the particular structure of the prior defined by the SGM to define a sequence of intermediate linear inverse problems. As the noise level decreases, the posteriors of these inverse problems get closer to the target posterior of the original inverse problem. To sample from this sequence of posteriors, we propose the use of Sequential Monte Carlo (SMC) methods. The proposed algorithm, MCGDiff, is shown to be theoretically grounded and we provide numerical simulations showing that it outperforms competing baselines when dealing with ill-posed inverse problems in a Bayesian setting.\n\n\nGenerative Flow Networks as Entropy-Regularized RL\nDaniil Tiapkin CMAP, École Polytechnique\nThe recently proposed generative flow networks (GFlowNets) are a method of training a policy to sample compositional discrete objects with probabilities proportional to a given reward via a sequence of actions. GFlowNets exploit the sequential nature of the problem, drawing parallels with reinforcement learning (RL). Our work extends the connection between RL and GFlowNets to a general case. We demonstrate how the task of learning a generative flow network can be efficiently redefined as an entropy-regularized RL problem with a specific reward and regularizer structure. Furthermore, we illustrate the practical efficiency of this reformulation by applying standard soft RL algorithms to GFlowNet training across several probabilistic modeling tasks. Contrary to previously reported results, we show that entropic RL approaches can be competitive against established GFlowNet training methods. This perspective opens a direct path for integrating reinforcement learning principles into the realm of generative flow networks.",
    "crumbs": [
      "Home",
      "2023",
      "November"
    ]
  },
  {
    "objectID": "sem/2024/s2024_12.html",
    "href": "sem/2024/s2024_12.html",
    "title": "December",
    "section": "",
    "text": "Salle 03, PariSanté Campus\n\n\nLearned Reference-based Diffusion Sampler for multi-modal distributions\nLouis Grenioux CMAP, École polytechnique\nOver the past few years, several approaches utilizing score-based diffusion have been proposed to sample from probability distributions, that is without having access to exact samples and relying solely on evaluations of unnormalized densities. The resulting samplers approximate the time-reversal of a noising diffusion process, bridging the target distribution to an easy-to-sample base distribution. In practice, the performance of these methods heavily depends on key hyperparameters that require ground truth samples to be accurately tuned. Our work aims to highlight and address this fundamental issue, focusing in particular on multi-modal distributions, which pose significant challenges for existing sampling methods. Building on existing approaches, we introduce Learned Reference-based Diffusion Sampler (LRDS), a methodology specifically designed to leverage prior knowledge on the location of the target modes in order to bypass the obstacle of hyperparameter tuning. LRDS proceeds in two steps by (i) learning a reference diffusion model on samples located in high-density space regions and tailored for multimodality, and (ii) using this reference model to foster the training of a diffusion-based sampler.\n\n\nGraph-informed importance sampling for piecewise deterministic Markov processes. Application in reliability assessment.\nGuillaume Chennetier CERMICS, École nationale des ponts et chaussées\nPiecewise Deterministic Markov Processes (PDMPs) describe deterministic dynamical systems with parameters subject to random jumps, making them versatile tools for modeling complex phenomena. However, generating their trajectories can be computationally expensive. For a large class of inference problems, an optimal sampling strategy exists and relies on a generalized version of the “committor function” of the process. We propose a novel adaptive importance sampling method to efficiently generate rare trajectories of PDMPs. The approach involves a two-phase process. In a first offline phase, the PDMP is approximated by a simpler process on a graph, enabling explicit computation of key quantities used to build a low-cost approximation of the committor function. In a second online phase, PDMP trajectories are generated using a distribution informed by this approximation and iteratively refined via cross-entropy minimization. We provide asymptotic guarantees and demonstrate the method’s effectiveness by estimating the failure probability of a complex industrial system.",
    "crumbs": [
      "Home",
      "2024",
      "December"
    ]
  },
  {
    "objectID": "sem/2024/s2024_04.html",
    "href": "sem/2024/s2024_04.html",
    "title": "April I",
    "section": "",
    "text": "Salle 06, PariSanté Campus\n\n\nAlpha-divergence Variational Inference Meets Importance Weighted Auto-Encoders: Methodology and Asymptotics\nKamélia Daudel ESSEC Business School\nVariational Inference methods are optimization-based methods that have generated a lot of attention in Bayesian Statistics due to their applicability to high-dimensional machine learning problems. In particular, several algorithms involving the Variational Rényi (VR) bound have been proposed to optimize an alpha-divergence between a target posterior distribution and a variational distribution. Despite promising empirical results, those algorithms resort to biased stochastic gradient descent procedures and thus lack theoretical guarantees. In this paper, we formalize and study the VR-IWAE bound, a generalization of the Importance Weighted Auto-Encoder (IWAE) bound. We show that the VR-IWAE bound enjoys several desirable properties and notably leads to the same stochastic gradient descent procedure as the VR bound in the reparameterized case, but this time by relying on unbiased gradient estimators. We then provide two complementary theoretical analyses of the VR-IWAE bound and thus of the standard IWAE bound. Those analyses shed light on the benefits or lack thereof of these bounds. Lastly, we illustrate our theoretical claims over toy and real-data examples.\nReference: K. Daudel, J. Benton, Y. Shi and A. Doucet (2023). Alpha-divergence Variational Inference Meets Importance Weighted Auto-Encoders: Methodology and Asymptotics. Journal of Machine Learning Research, 24(243):1−83.\n\n\nSampling from multimodal distributions with stochastic localization\nMaxence Noble CMAP, École Polytechnique\nBuilding upon score-based learning, new interest in stochastic localization techniques has recently emerged. In these models, one seeks to noise a sample from the data distribution through a stochastic process, called observation process, and progressively learns a denoiser associated to this dynamics. Apart from specific applications, the use of stochastic localization for the problem of sampling from an unnormalized target density has not been explored extensively. This work contributes to fill this gap. We consider a general stochastic localization framework and introduce an explicit class of observation processes, associated with flexible denoising schedules. We provide a complete methodology, Stochastic Localization via Iterative Posterior Sampling (SLIPS), to obtain approximate samples of these dynamics, and as a by-product, samples from the target distribution. Our scheme is based on a Markov chain Monte Carlo estimation of the denoiser and comes with detailed practical guidelines. We illustrate the benefits and applicability of SLIPS on the challenging setting of sampling from multimodal distributions.",
    "crumbs": [
      "Home",
      "2024",
      "April I"
    ]
  },
  {
    "objectID": "sem/2024/s2024_05.html",
    "href": "sem/2024/s2024_05.html",
    "title": "May",
    "section": "",
    "text": "Salle 06, PariSanté Campus\n\n\nImportance sampling with free energies and autoencoders for multimodal probability distributions\nGabriel Stoltz CERMICS, Ecole des Ponts and Matherials team-project, Inria Paris\nSampling high dimensional probability measures is often made difficult by the multimodality of the target probability distribution. The MCMC scheme under consideration needs to pass through low probability regions to switch from one mode to another, which is a rare event. An approach to making these transitions less rare is to identify a few selected (nonlinear) degrees of freedom of the system, which are at the origin of the slow mixing behavior, compute the associated free energies, and perform some importance sampling based on the latter function. This was considered in [1], based on manually selected variables (mostly linear function of the coordinates). Various tools have now recently been developed in molecular simulation to automatically find the most relevant nonlinear degrees of freedeom hindering sampling, based on machine learning tools such as autoencoders [2]. I will present a methodology to leverage these models for better sampling, and will also provide a mathematical analysis of the approach, relating it to principal manifolds and providing an interpretation based on conditional expectations [3]. \n\n[1] N. Chopin, T. Lelièvre and G. Stoltz, Free energy methods for efficient exploration of mixture posterior densities, Stat. Comput. 22(4), 897-916 (2012) \n[2] Z. Belkacemi, P. Gkeka, T. Lelièvre, G. Stoltz, Chasing collective variables using autoencoders and biased trajectories, J. Chem. Theory Comput. 18(1), 59-78 (2022)\n[3] T. Lelièvre, T. Pigeon, G. Stoltz and W. Zhang, Analyzing multimodal probability measures with autoencoders, J. Phys. Chem. B 128(11), 2607-2631 (2024)\n\n\nAdaptive MCMC sampling using a Metropolized PDMP sampler combined with a No-U-Turn criterion\nAugustin Chevallier Université de Strasbourg\nAdaptivity in MCMC algorithms is hard to achieve. In Hamiltonian Monte Carlo, for example, it is possible to tune the path length using the No-U-Turn sampler, but the numerical step size cannot be adapted; it can only be tuned. We propose here a new class of algorithm based on Metropolizing a numerical approximation of a PDMP sampler. Like HMC, these samplers require two parameters: a numerical step size and a path length. Unlike HMC, both parameters can be adapted. This paves the way for more robust sampling algorithms, especially for difficult target densities.",
    "crumbs": [
      "Home",
      "2024",
      "May"
    ]
  },
  {
    "objectID": "sem/2024/s2024_01.html",
    "href": "sem/2024/s2024_01.html",
    "title": "January",
    "section": "",
    "text": "Salle 07, PariSanté Campus\n\n\nCombining Normalizing Flows and Quasi-Monte Carlo\nCharly Andral Ceremade, Université Paris Dauphine-PSL\nRecent advances in machine learning have led to the development of new methods for enhancing Monte Carlo methods such as Markov chain Monte Carlo (MCMC) and importance sampling (IS). One such method is normalizing flows, which use a neural network to approximate a distribution by evaluating it pointwise. Normalizing flows have been shown to improve the performance of MCMC and IS. On the other side, (randomized) quasi-Monte Carlo methods are used to perform numerical integration. They replace the random sampling of Monte Carlo by a sequence which cover the hypercube more uniformly, resulting in better convergence rates for the error that plain Monte Carlo. In this work, we combine these two methods by using quasi-Monte Carlo to sample the initial distribution that is transported by the flow. We demonstrate through numerical experiments that this combination can lead to an estimator with significantly lower variance than if the flow was sampled with a classic Monte Carlo.\n\n\nOptimizing the diffusion of overdamped Langevin dynamics\nRégis Santet, CERMICS, École des Ponts & MATHERIALS, INRIA Paris\nOverdamped Langevin dynamics are reversible stochastic differential equations which are commonly used to sample probability measures in high dimensional spaces, such as the ones appearing in computational statistical physics and Bayesian inference. By varying the diffusion coefficient, there are in fact infinitely many reversible overdamped Langevin dynamics which preserve the target probability measure at hand. This suggests to optimize the diffusion coefficient in order to increase the convergence rate of the dynamics, as measured by the spectral gap of the generator associated with the stochastic differential equation. We analytically study this problem here, obtaining in particular necessary conditions on the optimal diffusion coefficient. We also derive an explicit expression of the optimal diffusion in some homogenized limit. Numerical results, both relying on discretizations of the spectral gap problem and Monte Carlo simulations of the stochastic dynamics, demonstrate the increased quality of the sampling arising from an appropriate choice of the diffusion coefficient.\nThis is joint work with Tony Lelièvre, Grigorios Pavliotis, Geneviève Robin and Gabriel Stoltz.",
    "crumbs": [
      "Home",
      "2024",
      "January"
    ]
  },
  {
    "objectID": "sem/2024/s2024_03.html",
    "href": "sem/2024/s2024_03.html",
    "title": "March",
    "section": "",
    "text": "Salle 03, PariSanté Campus\n\n\nTransporting measures for sampling: parametric and non-parametric approaches inspired by generative modelling\nMarylou Gabrié CMAP, École Polytechnique\nGenerative models and statistical mechanics have a long history of cross-fertilization. Recently, it has been shown that generative models, such as normalizing flows, can assist sampling of metastable systems. This remarkable ability comes from the high-expressivity of generative models that can approach complex distributions while remaining tractable. However, the training accuracy of generative models deteriorates when the dimension and complexity of the target measure are pushed. Inspired by recent progress in generative modelling relying on stochastic processes, non-parametric sampling algorithms can also be derived to sample from metastable systems. Are non-parametric methods more scalable?\n\n\nImplicit Diffusion: Efficient Optimization through Stochastic Sampling\nPierre Marion École Polytechnique Fédérale de Lausanne\nWe present a new algorithm to optimize distributions defined implicitly by parameterized stochastic diffusions. Doing so allows us to modify the outcome distribution of sampling processes by optimizing over their parameters. We introduce a general framework for first-order optimization of these processes, that performs jointly, in a single loop, optimization and sampling steps. This approach is inspired by recent advances in bilevel optimization and automatic implicit differentiation, leveraging the point of view of sampling as optimization over the space of probability distributions. We provide theoretical guarantees on the performance of our method, as well as experimental results demonstrating its effectiveness in real-world settings.",
    "crumbs": [
      "Home",
      "2024",
      "March"
    ]
  },
  {
    "objectID": "sem/summary_2024.html",
    "href": "sem/summary_2024.html",
    "title": "Seminars 2024",
    "section": "",
    "text": "January\n\n\n\n\n\n\n\n\n\n\n\nJan 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nFebruary\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMarch\n\n\n\n\n\n\n\n\n\n\n\nMar 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nApril I\n\n\n\n\n\n\n\n\n\n\n\nApr 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nApril II\n\n\n\n\n\n\n\n\n\n\n\nApr 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMay\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember\n\n\n\n\n\n\n\n\n\n\n\nSep 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nOctober\n\n\n\n\n\n\n\n\n\n\n\nOct 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nNovember\n\n\n\n\n\n\n\n\n\n\n\nNov 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDecember\n\n\n\n\n\n\n\n\n\n\n\nDec 13, 2024\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "2024"
    ]
  },
  {
    "objectID": "sem/2025/s2025_04.html",
    "href": "sem/2025/s2025_04.html",
    "title": "April",
    "section": "",
    "text": "Salle XX, PariSanté Campus\n\n\nTitle\nSusan Wei Monash University\nAbstract\n\n\nTitle\nSpeaker Affiliation\nAbstract",
    "crumbs": [
      "Home",
      "2025",
      "April"
    ]
  },
  {
    "objectID": "sem/2025/s2025_02.html",
    "href": "sem/2025/s2025_02.html",
    "title": "February",
    "section": "",
    "text": "Salle 03, PariSanté Campus\n\n\n\n\n\n\n\nSeminar time\n\n\n\nThis seminar is scheduled for 3PM (not the usual 4PM)\n\n\n\nTBA\nManon Michel LMBP, Université Clermont-Auvergne\nAbstract TBA\n\n\nTitle\nSpeaker Affiliation\nAbstract",
    "crumbs": [
      "Home",
      "2025",
      "February"
    ]
  },
  {
    "objectID": "sem/2025/s2025_01.html",
    "href": "sem/2025/s2025_01.html",
    "title": "January",
    "section": "",
    "text": "Salle 03, PariSanté Campus\n\n\nTitle\nJacopo Iollo INRIA Rhone-Alpes\nAbstract\n\n\nTitle\nSpeaker Affiliation\nAbstract",
    "crumbs": [
      "Home",
      "2025",
      "January"
    ]
  },
  {
    "objectID": "sem/2025/s2025_03.html",
    "href": "sem/2025/s2025_03.html",
    "title": "March",
    "section": "",
    "text": "Salle 03, PariSanté Campus\n\n\nTitle\nAndrea Pandolfi Università Bocconi\nAbstract\n\n\nTitle\nJulien Stoehr Université Paris Dauphine, PSL\nAbstract",
    "crumbs": [
      "Home",
      "2025",
      "March"
    ]
  },
  {
    "objectID": "sem/2025/s2025_05.html",
    "href": "sem/2025/s2025_05.html",
    "title": "May",
    "section": "",
    "text": "Room: Salle XX, PariSanté Campus\n\n\nTitle\nMartin Chak Università Bocconi\nAbstract\n\n\nTitle\nRémi Bardenet CNRS, Université de Lille\nAbstract"
  },
  {
    "objectID": "sem/2024/s2024_09.html",
    "href": "sem/2024/s2024_09.html",
    "title": "September",
    "section": "",
    "text": "Salle 03, PariSanté Campus\n\n\nProximal Interacting Particle Langevin Algorithms\nFrancesca Crucinio King’s College London\nWe introduce a class of algorithms, termed Proximal Interacting Particle Langevin Algorithms (PIPLA), for inference and learning in latent variable models whose joint probability density is non-differentiable. Leveraging proximal Markov chain Monte Carlo (MCMC) techniques and the recently introduced interacting particle Langevin algorithm (IPLA), we propose several variants within the novel proximal IPLA family, tailored to the problem of estimating parameters in a non-differentiable statistical model. We prove nonasymptotic bounds for the parameter estimates produced by the different algorithms in the strongly log-concave setting and provide comprehensive numerical experiments on various models to demonstrate the effectiveness of the proposed methods. In particular, we demonstrate the utility of our family of algorithms on a toy hierarchical example where our assumptions can be checked, as well as for sparse Bayesian logistic regression, training of sparse Bayesian neural networks, and sparse matrix completion. Our theory and experiments together show that PIPLA family can be the de facto choice for parameter estimation problems in non-differentiable latent variable models.\n\n\nNumerical Methods for SDEs with Irregular Coefficients\nTim Johnston Ceremade, Université Paris Dauphine-PSL\nIn this talk we discuss numerical methods for SDEs with irregular coefficients. We survey a number of results in the numerical analysis literature that demonstrate that the accuracy of numerical methods does not necessarily degenerate with the regularity of the drift coefficient. Finally we discuss applications to stochastic algorithms.",
    "crumbs": [
      "Home",
      "2024",
      "September"
    ]
  },
  {
    "objectID": "sem/2024/s2024_02.html",
    "href": "sem/2024/s2024_02.html",
    "title": "February",
    "section": "",
    "text": "Salle 07, PariSanté Campus\n\n\nSampling probability distributions on constrained spaces\nPierre Jacob ESSEC Business School\nI will describe the problem of designing MCMC samplers for probability distributions that are supported on submanifolds, and its relevance in statistics (hypothesis testing, Bayesian inference), and how one may implement couplings of such MCMC kernels. The question also arises when the target is supported in \\(R^d\\) and one wants to propose moves along the contour of the target density function, which could be well motivated, and has been suggested multiple times in the literature. Joint work with Elena Bortolato (Padova) and Robin Ryder (Paris-Dauphine).\n\n\nInsufficient Gibbs Sampling\nAntoine Luciano Ceremade, Université Paris Dauphine-PSL\nIn some applied scenarios, the availability of complete data is restricted, often due to privacy concerns, and only aggregated, robust and inefficient statistics derived from the data are accessible. These robust statistics are not sufficient, but they demonstrate reduced sensitivity to outliers and offer enhanced data protection due to their higher breakdown point. In this article, operating within a parametric framework, we propose a method to sample from the posterior distribution of parameters conditioned on different robust and inefficient statistics: specifically, the pairs (median, MAD) or (median, IQR), or one or more quantiles. Leveraging a Gibbs sampler and the simulation of latent augmented data, our approach facilitates simulation according to the posterior distribution of parameters belonging to specific families of distributions. We demonstrate its applicability on the Gaussian, Cauchy, and translated Weibull families.\n(Preprint: https://arxiv.org/abs/2307.14973)",
    "crumbs": [
      "Home",
      "2024",
      "February"
    ]
  },
  {
    "objectID": "sem/2024/s2024_11.html",
    "href": "sem/2024/s2024_11.html",
    "title": "November",
    "section": "",
    "text": "Auditorium, PariSanté Campus\n\n\nSaddlepoint Monte Carlo and its application to the statistical analysis of vote carryover in French elections\nNicolas Chopin ENSAE-CREST, Institut Polytechnique de Paris\nAssuming X is a random vector and A a non-invertible matrix, one sometimes need to perform inference while only having access to samples of Y = AX. The corresponding likelihood is typically intractable. One may still be able to perform exact Bayesian inference using a pseudo-marginal sampler, but this requires an unbiased estimator of the intractable likelihood. We propose saddlepoint Monte Carlo, a method for obtaining an unbiased estimate of the density of Y with very low variance, for any model belonging to an exponential family. Our method relies on importance sampling of the characteristic function, with insights brought by the standard saddlepoint approximation scheme with exponential tilting. We show that saddlepoint Monte Carlo makes it possible to perform exact inference on particularly challenging problems and datasets. We focus on the ecological inference problem, where one observes only aggregates at a fine level. We present in particular a study of the carryover of votes between the two rounds of various French elections, using the finest available data (number of votes for each candidate in about 60,000 polling stations over most of the French territory). We show that existing, popular approximate methods for ecological inference can lead to substantial bias, which saddlepoint Monte Carlo is immune from. We also present original results for the 2024 legislative elections on political centre-to-left and left-to-centre conversion rates when the far-right is present in the second round. Finally, we discuss other exciting applications for saddlepoint Monte Carlo, such as dealing with aggregate data in privacy or inverse problems.\nJoint work with Robin Ryder (Imperial) and Théo Voldoire (Harvard University). Link: https://arxiv.org/abs/2410.18243\n\n\nExact and approximate filtering via discrete dual processes\nGuillaume Kon Kam King INRAE\nExact inference for hidden Markov models requires the evaluation of all distributions of interest – filtering, prediction, smoothing and likelihood – with a finite computational effort. We provide sufficient conditions for exact inference for a class of hidden Markov models on general state spaces given a set of discretely collected indirect observations linked non linearly to the signal, and a set of practical algorithms for inference. The conditions we obtain are concerned with the existence of a certain type of dual process, which is an auxiliary process embedded in the time reversal of the signal, that in turn allows to represent the distributions and functions of interest as finite mixtures of elementary densities or products thereof. We then turn to a more general class of dual processes which do not provide computable expressions for the filtering distributions but countable mixtures indexed by the dual process state space. We investigate the performance of our strategies on two hidden Markov models driven by Cox–Ingersoll–Ross and Wright–Fisher diffusions.",
    "crumbs": [
      "Home",
      "2024",
      "November"
    ]
  },
  {
    "objectID": "sem/2024/s2024_04_sp.html",
    "href": "sem/2024/s2024_04_sp.html",
    "title": "April II",
    "section": "",
    "text": "Salle 08, PariSanté Campus\n\n\nMCMC when you do not want to evaluate the target distribution\nGuanyang Wang Rutgers University\nIn sampling tasks, it is common for target distributions to be known up to a normalizing constant. However, in many situations, evaluating even the unnormalized distribution can be costly or infeasible. This issue arises in scenarios such as sampling from the Bayesian posterior for large datasets and the ‘doubly intractable’ distributions. We provide a way to unify various MCMC algorithms, including several minibatch MCMC algorithms and the exchange algorithm. This framework not only simplifies the theoretical analysis of existing algorithms but also creates new algorithms. Similar frameworks exist in the literature, but they concentrate on different objectives.\n\n\n\n\n\n\nSpecial edition\n\n\n\nAll About That Bayes and Mostly Monte Carlo joint seminar!",
    "crumbs": [
      "Home",
      "2024",
      "April II"
    ]
  },
  {
    "objectID": "sem/2024/s2024_10.html",
    "href": "sem/2024/s2024_10.html",
    "title": "October",
    "section": "",
    "text": "Auditorium, PariSanté Campus\n\n\nSkew-symmetric schemes for SDEs and where to find them\nGiorgos Vasdekis Newcastle University\nLocally balancing algorithms are a new class of MCMC algorithms, recently introduced in (Livingstone and Zanella, 2022). One of these algorithms, the Barker algorithm, has been shown to be robust to heteroskedasticity of the posterior target and the step size of the algorithm. At the same time, the algorithm seems to preserve high dimensional properties of state-of-the-art MCMC, making it an interesting alternative to the existing literature. It turns out that in order to sample from the Barker algorithm, one can use ideas of sampling from skew-symmetric distributions. We will transfer these ideas in the context of simulating from diffusion processes and we will suggest a new class of unadjusted MCMC algorithms, which are robust with respect to the step size.\nThis is joint work with S. Livingstone, N. Nusken and R. Zhang.\n\n\nScalable sampling using annealing and sequential Monte Carlo samplers\nSaifuddin Syed Oxford University\nGenerating samples from complex probability distributions is a fundamental challenge in statistical modelling and Bayesian statistics. In practice, this is generally impossible, and we must introduce a simpler reference distribution, such as a Gaussian, and manipulate its density and samples to approximate the target. In general, direct inference is reliable when the reference is close to the target and fragile when it is not. Annealing is a popular technique motivated by this principle and introduces a sequence of distributions that interpolates between the reference and target, ensuring the neighbouring distributions are close enough. An annealing algorithm specifies how to traverse this bridge of distributions to incrementally transform samples from the reference into samples approximating the target.\nIn this talk, we will analyse a popular annealing algorithm, Sequential Monte Carlo Samplers (SMCS), which sequentially propagates samples from the reference to the target using importance sampling. We will see how SMCS’s performance scales with increasing runtime, parallelism, memory, and the difficulty of the inference problem. We will then use these theoretical insights to develop a black-box algorithm for efficiently tuning SMCS and related annealing algorithms.",
    "crumbs": [
      "Home",
      "2024",
      "October"
    ]
  },
  {
    "objectID": "sem/summary_2025.html",
    "href": "sem/summary_2025.html",
    "title": "Seminars 2025",
    "section": "",
    "text": "May\n\n\n\n\n\n\n\n\n\n\n\nDec 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nJanuary\n\n\n\n\n\n\n\n\n\n\n\nJan 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nFebruary\n\n\n\n\n\n\n\n\n\n\n\nFeb 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMarch\n\n\n\n\n\n\n\n\n\n\n\nMar 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nApril\n\n\n\n\n\n\n\n\n\n\n\nApr 11, 2025\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "2025"
    ]
  },
  {
    "objectID": "sem/2023/s2023_10.html",
    "href": "sem/2023/s2023_10.html",
    "title": "October",
    "section": "",
    "text": "Salle 07, PariSanté Campus\n\n\nPiecewise deterministic sampling with splitting schemes\nAndrea Bertazzi CMAP, École Polytechnique \nPiecewise deterministic Markov processes (PDMPs) received substantial interest in recent years as an alternative to classical Markov chain Monte Carloalgorithms. While theoretical properties of PDMPs have been studied extensively, their practical implementation remains limited to specific applications in which bounds on the gradient of the negative log-target can be derived. In order to address this problem, we propose to approximate PDMPs using splitting schemes, that means simulating the deterministic dynamics and the random jumps in two different stages. We show that symmetric splittings of PDMPs are of second order. Then we focus on the Zig-Zag sampler (ZZS) and show how to remove the bias of the splitting scheme with a skew reversible Metropolis filter. Finally, we illustrate with numerical simulations the advantages of our proposed scheme over competitors.\n\n\nBayesian score calibration for approximate models\nJoshua Bon Ceremade, Université Paris Dauphine-PSL\nScientists continue to develop increasingly complex mechanistic models to reflect their knowledge more realistically. Statistical inference using these models can be challenging since the corresponding likelihood function is often intractable and model simulation may be computationally burdensome.  Fortunately, in many of these situations, it is possible to adopt a surrogate model or approximate likelihood function.  It may be convenient to base Bayesian inference directly on the surrogate, but this can result in bias and poor uncertainty quantification.  In this paper we propose a new method for adjusting approximate posterior samples to reduce bias and produce more accurate uncertainty quantification.  We do this by optimizing a transform of the approximate posterior that maximizes a scoring rule.  Our approach requires only a (fixed) small number of complex model simulations and is numerically stable.  We demonstrate good performance of the new method on several examples of increasing complexity.",
    "crumbs": [
      "Home",
      "2023",
      "October"
    ]
  },
  {
    "objectID": "sem/summary_2023.html",
    "href": "sem/summary_2023.html",
    "title": "Seminars 2023",
    "section": "",
    "text": "October\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nNovember\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDecember\n\n\n\n\n\n\n\n\n\n\n\nDec 15, 2023\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "2023"
    ]
  },
  {
    "objectID": "psc_rooms.html",
    "href": "psc_rooms.html",
    "title": "Rooms at PariSanté",
    "section": "",
    "text": "Location: PariSanté Campus\n\nMore information on travelling to PariSanté and the facilities is available here."
  }
]